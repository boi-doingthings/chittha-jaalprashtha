[
  {
    "objectID": "posts/pytorch-part1/index.html",
    "href": "posts/pytorch-part1/index.html",
    "title": "PyTorch Notes-I",
    "section": "",
    "text": "Two primitives\n- `torch.utils.data.DataLoader` --> Map-Style\n- `torch.utils.data.Dataset` --> Iterable-Style\n\nMap-Style : A map-style dataset is one that implements the getitem() and len() protocols, and represents a map from (possibly non-integral) indices/keys to data samples.\n\nUseful for:\n\nRead the data values at some i-th index in the dataset. Think like pandas dataframe indexing.\n\n\nIterable-Style: An iterable-style dataset is an instance of a subclass of IterableDataset that implements the iter() protocol, and represents an iterable over data samples.\n\nUseful for:\n\nCases when random reads are expensive.\nBatch size is data dependent.\n\n\n\n\nimport torch\nfrom torch.utils.data import DataLoader\n\n\nTorch\n\nTorchVision\n\ndatasets\n\nTorchText\nTorchAudio\n\n\n\nfrom torchvision import datasets\nfrom torchvision.transforms import ToTensor\n\n\ntrain_data = datasets.FashionMNIST(root=\"./data\", # where is data stored or to be stored\n                                   train=True, # datasets contain predefined split\n                                   download=True, #Download if not present\n                                   transform =ToTensor()\n                                  )\n\n# Download test data from open datasets.\ntest_data = datasets.FashionMNIST(\n    root=\"data\",\n    train=False,\n    download=True,\n    transform=ToTensor(),\n)\n\n\ntrain_data.data.shape\n\ntorch.Size([60000, 28, 28])\n\n\n\ntrain_data.classes\n\n['T-shirt/top',\n 'Trouser',\n 'Pullover',\n 'Dress',\n 'Coat',\n 'Sandal',\n 'Shirt',\n 'Sneaker',\n 'Bag',\n 'Ankle boot']\n\n\n\ntrain_data.class_to_idx\n\n{'T-shirt/top': 0,\n 'Trouser': 1,\n 'Pullover': 2,\n 'Dress': 3,\n 'Coat': 4,\n 'Sandal': 5,\n 'Shirt': 6,\n 'Sneaker': 7,\n 'Bag': 8,\n 'Ankle boot': 9}\n\n\n\ntrain_data.targets\n\ntensor([9, 0, 0,  ..., 3, 0, 5])\n\n\n\ntrain_data.transforms\n\nStandardTransform\nTransform: ToTensor()\n\n\n\ntrain_data.training_file\n\n'training.pt'\n\n\n\ntrain_data.train\n\nTrue\n\n\n\ntest_data.train\n\nFalse\n\n\nDataset is DataLoader’s argument.\nBenefits as it supports: 1. Automatic Batching 2. Sampling 3. Shuffling 4. Multiprocess data loading.\n\nbatch_size = 128\n\n# Create data loaders.\ntrain_dataloader = DataLoader(train_data, batch_size=batch_size)\ntest_dataloader = DataLoader(test_data, batch_size=batch_size)\n\nfor X, y in test_dataloader:\n    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n    print(f\"Shape of y: {y.shape} {y.dtype}\")\n\n    break\n\nShape of X [N, C, H, W]: torch.Size([512, 1, 28, 28])\nShape of y: torch.Size([512]) torch.int64\n\n\n\ntest_data.data.shape\n\ntorch.Size([10000, 28, 28])\n\n\n\nlen(test_dataloader)\n\n20\n\n\n\nprint(test_data.data.shape[0]/batch_size)\n\n19.53125"
  },
  {
    "objectID": "posts/pytorch-part1/index.html#model-creation",
    "href": "posts/pytorch-part1/index.html#model-creation",
    "title": "PyTorch Notes-I",
    "section": "Model Creation",
    "text": "Model Creation\nIn Pytorch, a model is a class that inherits from the nn.Module. There are two main components of model class:\n\nA function __init__() : This stores the model components like: layers, dropouts etc\n\nA function forward(): The forward flow of data in the model i.e how data flows from one layer to another.\n\n\n# Get cpu or gpu device for training.\ndevice = \"cuda:1\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"Using {device} device\")\n\nUsing cuda:1 device\n\n\n\nfrom torch import nn\n# Define Model\n\nclass NNet(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.flatten = nn.Flatten()\n        self.relu = nn.ReLU()\n        self.linear1 = nn.Linear(28*28,512)\n        self.linear2 = nn.Linear(512,256*2)\n        self.linear3 = nn.Linear(256*2,10)\n        \n    def forward(self,x):\n        '''\n        x : denotes the input data that will flow through the model\n        '''\n        x = self.flatten(x)\n        x = self.relu(self.linear1(x))\n        x = self.relu(self.linear2(x))\n        return self.linear3(x)\n    \nmodel = NNet().to(device)\nprint(model)\n        \n        \n        \n    \n\nNNet(\n  (flatten): Flatten(start_dim=1, end_dim=-1)\n  (relu): ReLU()\n  (linear1): Linear(in_features=784, out_features=512, bias=True)\n  (linear2): Linear(in_features=512, out_features=512, bias=True)\n  (linear3): Linear(in_features=512, out_features=10, bias=True)\n)\n\n\n\nLoss\nThe metric indicator of the scale of how right or wrong our predictions are against the actual distributions. ### Optimizer The process that update the weights to minimize the loss.\n\nloss_fn = nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n\n\nlen(train_dataloader)\n\n118\n\n\n\ndef train(dataloader,model,loss_fn,optimizer):\n    # You can directly apply the len function on dataloader.dataset to get the number of entries in the dataset.\n    # Doing this on the dataloader returns the number of iteables formed\n    size = len(dataloader.dataset) \n    model.train() #model in training mode\n    for batch, (X,y) in enumerate(dataloader):\n        X,y = X.to(device), y.to(device)\n        \n        # Compute prediction error\n        pred = model(X)\n        loss = loss_fn(pred, y)\n\n        # Backpropagation\n        optimizer.zero_grad() # clear the gradients and set to zero\n        loss.backward() # do backprop\n        optimizer.step() # udpate the gradients\n        \n        if batch % 50 == 0:\n            loss, current = loss.item(), batch * len(X)\n            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n        \n    \n\n\ndef test(dataloader, model, loss_fn):\n    size = len(dataloader.dataset)\n    num_batches = len(dataloader)\n    model.eval() #model in eval mode so no gradient updates\n    test_loss, correct = 0, 0\n    with torch.no_grad():\n        for X, y in dataloader:\n            X, y = X.to(device), y.to(device)\n            pred = model(X)\n            test_loss += loss_fn(pred, y).item()\n            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n    test_loss /= num_batches\n    correct /= size\n    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n\n\n%%time\nepochs = 8\nfor t in range(epochs):\n    print(f\"Epoch {t+1}\\n-------------------------------\")\n    train(train_dataloader, model, loss_fn, optimizer)\n    test(test_dataloader, model, loss_fn)\nprint(\"Done!\")\n\nEpoch 1\n-------------------------------\nloss: 2.294676  [    0/60000]\nloss: 2.288279  [25600/60000]\nloss: 2.275253  [51200/60000]\nTest Error: \n Accuracy: 23.6%, Avg loss: 2.275554 \n\nEpoch 2\n-------------------------------\nloss: 2.277005  [    0/60000]\nloss: 2.270516  [25600/60000]\nloss: 2.256798  [51200/60000]\nTest Error: \n Accuracy: 29.2%, Avg loss: 2.257794 \n\nEpoch 3\n-------------------------------\nloss: 2.259315  [    0/60000]\nloss: 2.252728  [25600/60000]\nloss: 2.238159  [51200/60000]\nTest Error: \n Accuracy: 32.6%, Avg loss: 2.239789 \n\nEpoch 4\n-------------------------------\nloss: 2.241425  [    0/60000]\nloss: 2.234566  [25600/60000]\nloss: 2.219000  [51200/60000]\nTest Error: \n Accuracy: 36.0%, Avg loss: 2.221168 \n\nEpoch 5\n-------------------------------\nloss: 2.222970  [    0/60000]\nloss: 2.215658  [25600/60000]\nloss: 2.198995  [51200/60000]\nTest Error: \n Accuracy: 40.5%, Avg loss: 2.201538 \n\nEpoch 6\n-------------------------------\nloss: 2.203543  [    0/60000]\nloss: 2.195568  [25600/60000]\nloss: 2.177734  [51200/60000]\nTest Error: \n Accuracy: 45.4%, Avg loss: 2.180485 \n\nEpoch 7\n-------------------------------\nloss: 2.182732  [    0/60000]\nloss: 2.173880  [25600/60000]\nloss: 2.154761  [51200/60000]\nTest Error: \n Accuracy: 49.2%, Avg loss: 2.157631 \n\nEpoch 8\n-------------------------------\nloss: 2.160224  [    0/60000]\nloss: 2.150239  [25600/60000]\nloss: 2.129723  [51200/60000]\nTest Error: \n Accuracy: 51.6%, Avg loss: 2.132602 \n\nDone!\nCPU times: user 24.9 s, sys: 184 ms, total: 25 s\nWall time: 25.2 s"
  },
  {
    "objectID": "posts/travel-hacks/index.html",
    "href": "posts/travel-hacks/index.html",
    "title": "Travel Hacks",
    "section": "",
    "text": "Always get the tyre pressures checked before embarking any journey. It is crucial for vehicle stability and mileage.\nInvest some money and get a dashcam and mobile stand installed. Dashcam feeds are the best evidence in case of a mishap.\nOn a foggy road, always drive behind a bigger vehicle say a truck or bus. But be sure to maintain sufficient distance.\nWhile driving if a person suddenly comes on the road crossing your path, act as follows:\n\nFor Kids: Try to turn vehicle in the direction opposite of child’s motion.\nFor Elderly: Remain in your line and brake, they mostly a backstep\nFor Women: Slow down as quickly as you can.\n\nNever switch ON AC and slow music, while you are the lone driver in a night.\n\n\n\n\n\nOn a roadways bus, try to get a seat between both axles. Never sit above the back axle.\n\n\n\n\n\n\n\nAlways do Ticket Booking from IRCTC’s site under your own login credentials.\nWhen unable to get a ticket but travel is compulsary, use this site. This gives you station A to station B seat wise availability, so that you can get a part ticket via the Train Ticket Examiner (TTE).\nWhen travelling alone, prefer to take upper birth if your height is above 5’7” (170CM) else take the Side Upper.\n\n\n\n\n\n\n\nUse SkyScanner and MMT to get the quotes. Third Party sites will give you ₹1000 cashback and then charge ₹1100 in convinience fees.\nVistara > Indigo > Jet Airways > SpiceJet : General Preference but yeah prices matter."
  },
  {
    "objectID": "posts/travel-hacks/index.html#id",
    "href": "posts/travel-hacks/index.html#id",
    "title": "Travel Hacks",
    "section": "ID",
    "text": "ID\n\nA secondary SIM Card.\nAlways keep a xerox copy of your Passport and other ID cards.\nA backup Credit Card."
  },
  {
    "objectID": "posts/travel-hacks/index.html#foods",
    "href": "posts/travel-hacks/index.html#foods",
    "title": "Travel Hacks",
    "section": "Foods",
    "text": "Foods\n\nDry Fruits and Chocolates\nEnergy Bars and Musli\nFruits if possible\nAvoid Chips/Biscuits/Maggi Noodles.\nA flask of liqour\nMini Saches of Milk Powder, Sugar and Coffee/Tea."
  },
  {
    "objectID": "posts/travel-hacks/index.html#medicine",
    "href": "posts/travel-hacks/index.html#medicine",
    "title": "Travel Hacks",
    "section": "Medicine",
    "text": "Medicine\n\nLoose Motions\nHeadache and Fevers\nQuick Bandages and disinfectant\nRegular Medications (if Any)"
  },
  {
    "objectID": "posts/travel-hacks/index.html#tools",
    "href": "posts/travel-hacks/index.html#tools",
    "title": "Travel Hacks",
    "section": "Tools",
    "text": "Tools\n\nA Swiss Knife : Trust me, its an invaluable investment.\nTorch\nPen and Paper\nA piece of Chalk"
  },
  {
    "objectID": "posts/travel-hacks/index.html#clothing",
    "href": "posts/travel-hacks/index.html#clothing",
    "title": "Travel Hacks",
    "section": "Clothing",
    "text": "Clothing\n\nA hand towel\nA extra pair of socks and innerwear."
  },
  {
    "objectID": "posts/my-travel-bag/index.html",
    "href": "posts/my-travel-bag/index.html",
    "title": "My Travel Bag",
    "section": "",
    "text": "An extra pair of socks and undergarments always.\nSet of microfiber towels [S+L].\nNeck Pillow and Sleep Mask\nTissue Papers\n\n\n\n\n\nSnickers\nEnergy/Protein Bars\nDry Fruits / Nuts / Chocolates\n\n\n\n\nA small plastic box that can contain a number of small things.\n\n\nKeep a note saved in your preferred notes app with a symptom to medicine mapping and date of expiry (DoE).\nFurther, a prescription from a doc that lists the medicines in general is helpful in international travel.\nNote: Always keep the meds in covers with name and DoE visible.\n\nAnalgesics –> pain, inflammation\n\nAntihistamines –> common cold, flu and allergies\n\nAntacids –> Acid Reflux\n\nMotion Sickness and Diarrhoea\n\nYour Regular Medications (if any)\n\n\n\n\n\nSmall packets of coffee/tea,sugar and powder milk.\nA mini sewing set.\nA todo sticky note pad.\nA multicolor pen.\nFew pieces of chalk\nA compass\nA small lock\nFew sanitary bags\n\n\n\n\n\nGLOBAL RULE: CASH IS KING.\n\nDomestic (in India):\n\nKeep a seperate a/c for UPI payments. Preferably use a Payments Bank.\nPRO TIP: Only keep enough money as per your budget.\n\nAlways carry a Debit Card for availing cash in need.\n\nA Visa/Mastercard with reduced limits for the travel duration.\n(Extremly useful in case of card fraud or theft)\n\n\nInternational:\n\nKeep the local currency.\n\nUse the GoNiyo Global Card to avoid forex.\n\nA Visa/Mastercard CC\n\n\n\n\n\n\nLiquids Kit\n\nShampoo\nBodywash\nFacewash\nMoisturiser\nSanitizers (<350 mL)\nDeodorant\n\nA Swiss Knife (I recommend the Handyman).\n(Never carry in cabin luggage as IACA considers it a potential weapon. Always put in checked in luggage with proper covering to avoid harm to baggage handlers)."
  },
  {
    "objectID": "posts/places_visit/index.html",
    "href": "posts/places_visit/index.html",
    "title": "My Travels",
    "section": "",
    "text": "I am an avid traveller and is always up for the next trip with my friends.\n\n\n\n\n\n\nKurukshetra\n\nNational Institute of Technology\nBrahma Sarovar\nJyotisar\nKrishna Museum\nPanorama & Science Centre\nSheikh Chili Masoleum\nKalpana Chawla Memorial Planetorium\nKurukshetra University\n\nKarnal\nAmbala\nPanchkula\nPanipat\n\n\n\n\n\nSolan -> Kasauli\n\nMonkey Point\nGilbert Trail\nMonkey (Manki) Point\nMall Road\n\nShimla\n\nNarkanda -> Hatu Peak -> Hatu Mata Temple\nNarkanda -> Tannu Jubar Lake\nMall Road\n\nKullu\n\nKasol\nBhuntar\nManikaran Sahib and Hot Springs\nTosh\nParvati Valley\nChalal\n\nKangra -> Dharamshala\n\nTriund\nMoon Peak\nMcLeodganj\nBhagsunag Falls\n\n\n\n\n\n\nJaipur\nUdaipur\nKota\n\n\n\n\n\nNorth Goa\n\nBeaches\n\nArambol\nBaga\nCalangute\nCandolim\n\n\nSouth Goa\n\nBeaches\n\nPalolem (Fav)\nAgonda\nMorjim\n\n\n\n\n\n\n\nMumbai\n\nMarine Drive\nGateway of India\nDalal Street\nBandra-Worli Sealink\nBandra\nCST\nNariman Point\nTravel in Mumbai Local\n\nPune\nLonavala\n\n\n\n\n\nTirupati\n\nSri Venkateshwara Temple (Balaji)\n\n\n\n\n\n\nMathura\n\nEverywhere :)\n\nAgra\n\nTaj Mahal\nAgra Fort\nAkbar Tomb\n\n\n\n\n\n\nIndore\n\n56 Food Street\nSarafa Bazar (Over-Rated)\nRalamandal Wildlife Sanctuary\n\nUjjain\n\nMahakaleshwar Jyotirlinga\nBhairo Baba Temple\n\n\n\n\n\n\nAlmost Everywhere :)\n\n\n\n\n\nUttar Kannada\n\nGokarna\n\nOm Beach\nKudle Beach\nMahabaleshwar Temple\n\nBhatkal\n\nMurudeshwar Temple\n\n\nBengaluru\n\nTraffic :|\nIndian Institute of Science (IISc)\nCubbon Park\nVisvesvaraya Industrial & Technological Museum\nLal Bagh Botanical Garden\nCity Market"
  },
  {
    "objectID": "posts/pytorch-object-detection/index.html",
    "href": "posts/pytorch-object-detection/index.html",
    "title": "Object Detection",
    "section": "",
    "text": "We try to understand code provided in this tutorial"
  },
  {
    "objectID": "posts/pytorch-object-detection/index.html#fintuning",
    "href": "posts/pytorch-object-detection/index.html#fintuning",
    "title": "Object Detection",
    "section": "FinTuning",
    "text": "FinTuning\n\nimport torchvision\nfrom torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n\n# load a model pre-trained on COCO\nmodel = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights=\"DEFAULT\")\n\n# replace the classifier with a new one, that has\n# num_classes which is user-defined\nnum_classes = 2  # 1 class (person) + background\n# get number of input features for the classifier\nin_features = model.roi_heads.box_predictor.cls_score.in_features\n# replace the pre-trained head with a new one\nmodel.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n\nDownloading: \"https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\" to /home/boi-doingthings/.cache/torch/hub/checkpoints/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\n\n\n\n\n\n\nimport torchvision\nfrom torchvision.models.detection.faster_rcnn import FastRCNNPredictor\nfrom torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n\n\ndef get_model_instance_segmentation(num_classes):\n    # load an instance segmentation model pre-trained on COCO\n    model = torchvision.models.detection.maskrcnn_resnet50_fpn(weights=\"DEFAULT\")\n\n    # get number of input features for the classifier\n    in_features = model.roi_heads.box_predictor.cls_score.in_features\n    # replace the pre-trained head with a new one\n    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n\n    # now get the number of input features for the mask classifier\n    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n    hidden_layer = 256\n    # and replace the mask predictor with a new one\n    model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask,\n                                                       hidden_layer,\n                                                       num_classes)\n\n    return model"
  },
  {
    "objectID": "posts/pytorch-transforms/index.html",
    "href": "posts/pytorch-transforms/index.html",
    "title": "Hands-on with Transforms",
    "section": "",
    "text": "Transforms are used to bring the data in a format that is suitable to build models on.\nThey can be applied both on the features/raw data and the labels as well."
  },
  {
    "objectID": "posts/pytorch-transforms/index.html#import-and-path-setups",
    "href": "posts/pytorch-transforms/index.html#import-and-path-setups",
    "title": "Hands-on with Transforms",
    "section": "Import and Path Setups",
    "text": "Import and Path Setups\n\nfrom pathlib import Path\n\n## Do the imports\nfrom torchvision.io import read_image\nfrom torch.utils.data import Dataset\n\nimport glob\n\nimport matplotlib.pyplot as plt\n\n\nbase_path = '/home/boi-doingthings/Documents/datasets/child_or_adult/'\n\n\ntrain_dir = base_path + 'train/'\ntest_dir = base_path + 'test/'\n\n\nprint('Train:',train_dir)\nprint('Test:',test_dir)\n\nTrain: /home/boi-doingthings/Documents/datasets/child_or_adult/train/\nTest: /home/boi-doingthings/Documents/datasets/child_or_adult/test/\n\n\n\ntrain_files_path = []\ntrain_files_labels = []\nfor file in glob.glob(train_dir+\"*/*\"):\n    train_files_path.append(file)\n    train_files_labels.append(file.split('/')[-2])\n\n\ntest_files_path = []\ntest_files_labels = []\nfor file in glob.glob(test_dir+\"*/*\"):\n    test_files_path.append(file)\n    test_files_labels.append(file.split('/')[-2])"
  },
  {
    "objectID": "posts/pytorch-transforms/index.html#create-dataset",
    "href": "posts/pytorch-transforms/index.html#create-dataset",
    "title": "Hands-on with Transforms",
    "section": "Create Dataset",
    "text": "Create Dataset\n\nclass CvA_Dataset(Dataset):\n    def __init__(self,labels,files):\n        self.labels = labels\n        self.files = files\n        \n    def __len__(self):\n        return len(self.files)\n    \n    def __getitem__(self,idx):\n        image = read_image(self.files[idx])\n        label = self.labels[idx]\n        return image,label\n\n\nTrain\n\ntrain = CvA_Dataset(train_files_labels,train_files_path)\n\n\nplt.imshow(train[101][0].permute(1,2,0))\nprint(train[101][1])\n\nadults\n\n\n\n\n\n\nlen(train)\n\n680\n\n\n\ntrain[101][0]\n\ntensor([[[127, 129, 130,  ..., 154, 153, 152],\n         [128, 130, 131,  ..., 154, 153, 152],\n         [130, 131, 132,  ..., 155, 154, 153],\n         ...,\n         [ 70,  72,  73,  ...,  57,  55,  53],\n         [ 66,  68,  71,  ...,  59,  55,  54],\n         [ 67,  68,  72,  ...,  55,  53,  51]],\n\n        [[164, 166, 167,  ..., 182, 181, 180],\n         [165, 167, 168,  ..., 182, 181, 180],\n         [167, 168, 169,  ..., 183, 182, 181],\n         ...,\n         [102, 104, 105,  ...,  57,  54,  52],\n         [100, 102, 103,  ...,  56,  54,  53],\n         [101, 102, 104,  ...,  52,  52,  50]],\n\n        [[180, 182, 183,  ..., 193, 192, 191],\n         [181, 183, 184,  ..., 193, 192, 191],\n         [183, 184, 185,  ..., 194, 193, 192],\n         ...,\n         [101, 103, 104,  ...,  49,  50,  48],\n         [ 99, 101, 102,  ...,  49,  50,  49],\n         [100, 101, 103,  ...,  45,  48,  46]]], dtype=torch.uint8)\n\n\nAs we can see the tensor is not in desired format, we want them to be values between [0,1]."
  },
  {
    "objectID": "posts/pytorch-dataloaders/index.html",
    "href": "posts/pytorch-dataloaders/index.html",
    "title": "Hands-on with DataLoaders",
    "section": "",
    "text": "We will try to create our custom dataloader for a dataset, outside the of datasets that come along inbuilt with the Pytorch sister libraries. For now, we are using a image dataset outside of Pytorch and sourced from a kaggle dataset, named Childeren vs Adults Classification. Please ensure to extract the compressed zip."
  },
  {
    "objectID": "posts/pytorch-dataloaders/index.html#import-and-path-setups",
    "href": "posts/pytorch-dataloaders/index.html#import-and-path-setups",
    "title": "Hands-on with DataLoaders",
    "section": "Import and Path Setups",
    "text": "Import and Path Setups\n\nfrom pathlib import Path\n\n## Do the imports\nfrom torchvision.io import read_image\nfrom torch.utils.data import Dataset\n\nimport glob\n\nimport matplotlib.pyplot as plt\n\n\nbase_path = '/home/boi-doingthings/Documents/datasets/child_or_adult/'\n\n\ntrain_dir = base_path + 'train/'\ntest_dir = base_path + 'test/'\n\n\nprint('Train:',train_dir)\nprint('Test:',test_dir)\n\nTrain: /home/boi-doingthings/Documents/datasets/child_or_adult/train/\nTest: /home/boi-doingthings/Documents/datasets/child_or_adult/test/\n\n\n\ntrain_files_path = []\ntrain_files_labels = []\nfor file in glob.glob(train_dir+\"*/*\"):\n    train_files_path.append(file)\n    train_files_labels.append(file.split('/')[-2])\n\n\ntest_files_path = []\ntest_files_labels = []\nfor file in glob.glob(test_dir+\"*/*\"):\n    test_files_path.append(file)\n    test_files_labels.append(file.split('/')[-2])"
  },
  {
    "objectID": "posts/pytorch-dataloaders/index.html#create-dataset",
    "href": "posts/pytorch-dataloaders/index.html#create-dataset",
    "title": "Hands-on with DataLoaders",
    "section": "Create Dataset",
    "text": "Create Dataset\n\nclass CvA_Dataset(Dataset):\n    def __init__(self,labels,files):\n        self.labels = labels\n        self.files = files\n        \n    def __len__(self):\n        return len(self.files)\n    \n    def __getitem__(self,idx):\n        image = read_image(self.files[idx])\n        label = self.labels[idx]\n        return image,label\n\n\nTrain\n\ntrain = CvA_Dataset(train_files_labels,train_files_path)\n\n\nplt.imshow(train[101][0].permute(1,2,0))\nprint(train[101][1])\n\nadults\n\n\n\n\n\n\nlen(train)\n\n680\n\n\n\n\nTest\n\ntest = CvA_Dataset(test_files_labels,test_files_path)\n\n\nplt.imshow(test[78][0].permute(1,2,0))\nprint(test[78][1])\n\nchildren\n\n\n\n\n\n\nlen(test)\n\n120"
  },
  {
    "objectID": "posts/pytorch-dataloaders/index.html#create-dataloaders",
    "href": "posts/pytorch-dataloaders/index.html#create-dataloaders",
    "title": "Hands-on with DataLoaders",
    "section": "Create DataLoaders",
    "text": "Create DataLoaders\n\nfrom torch.utils.data import DataLoader\n\n\nTrain\n\ntrain_data_loader = DataLoader(train,batch_size=16,shuffle=True)\n\n\nfor i in next(iter(train_data_loader)):\n    print(len(i))\n\n16\n16\n\n\n\n\nTest\n\ntest_data_loader = DataLoader(test,batch_size=16,shuffle=True)\n\n\nfor i in next(iter(test_data_loader)):\n    print(len(i))\n\n16\n16"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Hello! I am Yash Gupta aka boi-doingthings. I am interested in using Data Science to solve business problems."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Boi-DoingThings Blog",
    "section": "",
    "text": "My Travel Bag\n\n\n\n\n\n\n\ntravel\n\n\n\n\nA few of the essentials I carry on travels.\n\n\n\n\n\n\nDec 26, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTravel Hacks\n\n\n\n\n\n\n\ntravel\n\n\n\n\nSome key pointers I have learnt travelling so far.\n\n\n\n\n\n\nOct 3, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObject Detection\n\n\n\n\n\n\n\npytorch\n\n\njupyter\n\n\n\n\nCreate our own fine-tuned models\n\n\n\n\n\n\nSep 21, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on with Transforms\n\n\n\n\n\n\n\npytorch\n\n\njupyter\n\n\n\n\nApply transforms on our own datasets\n\n\n\n\n\n\nSep 19, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPyTorch Notes-I\n\n\n\n\n\n\n\njupyter\n\n\npytorch\n\n\n\n\nHands-on learning Pytorch from Pytorch Documentation\n\n\n\n\n\n\nSep 18, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on with DataLoaders\n\n\n\n\n\n\n\npytorch\n\n\njupyter\n\n\n\n\nCreate our own dataloaders\n\n\n\n\n\n\nSep 18, 2022\n\n\n\n\n\n\n  \n\n\n\n\nMy Travels\n\n\n\n\n\n\n\ntravel\n\n\n\n\nA list of places I have been.\n\n\n\n\n\n\nSep 17, 2022\n\n\n\n\n\n\nNo matching items"
  }
]